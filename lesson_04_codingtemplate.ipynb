{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade pip\n",
    "#!pip3 install --upgrade torch\n",
    "#!pip3 install --upgrade torchtext\n",
    "\n",
    "#some handy modules that I use often\n",
    "import datetime\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These declarations let plots display in Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, if you encounter a \"ModuleNotFoundError\", you can install from inside the jupyter notebook using !pip install *yourmodule* (you may need to restart your Jupyter instance to see the impact of your install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [dill package index](https://pypi.python.org/pypi/dill)\n",
    "* [spacy package index](https://pypi.python.org/pypi/spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as dill\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [fastai.learner on github](https://github.com/fastai/fastai/blob/master/fastai/learner.py)\n",
    "* [fastai.rnn_reg on github](https://github.com/fastai/fastai/blob/master/fastai/rnn_reg.py)\n",
    "* [fastai.rnn_train on github](https://github.com/fastai/fastai/blob/master/fastai/rnn_train.py)\n",
    "* [fastai.nlp on github](https://github.com/fastai/fastai/blob/master/fastai/nlp.py) - depends on the spacy module. [Solution for OSError: Can't find model 'en'](http://forums.fast.ai/t/lesson-4-oserror-cant-find-model-en/11252)\n",
    "* [fastai.lm_rnn on github](https://github.com/fastai/fastai/blob/master/fastai/lm_rnn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [pytorch/text (torchtext) on github](https://github.com/pytorch/text)\n",
    "    * [torchtext vocab on github](https://github.com/pytorch/text/blob/master/torchtext/vocab.py)\n",
    "    * [torchtext.datasets language_modeling on github](https://github.com/pytorch/text/blob/master/torchtext/datasets/language_modeling.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [large movie view dataset](http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The **sentiment classification task** consists of predicting the polarity (positive or negative) of a given text.\n",
    "\n",
    "However, before we try to classify *sentiment*, we will simply try to create a *language model*; that is, a model that can predict the next word in a sentence. Why? Because our model first needs to understand the structure of English, before we can expect it to recognize positive vs negative sentiment.\n",
    "\n",
    "So our plan of attack is the same as we used for Dogs v Cats: pretrain a model to do one thing (predict the next word), and fine tune it to do something else (classify sentiment).\n",
    "\n",
    "Unfortunately, there are no good pretrained language models available to download, so we need to create our own. To follow along with this notebook, we suggest downloading the dataset from [this location](http://files.fast.ai/data/aclImdb.tgz) on files.fast.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set the project level parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH data/aclImdb/\n",
      "TRN_PATH train/all/\n",
      "VAL_PATH test/all/\n",
      "TRN data/aclImdb/train/all/\n",
      "VAL data/aclImdb/test/all/\n",
      "MODELS data/aclImdb/models/\n",
      "FILES {'train': 'train/all/', 'validation': 'test/all/', 'test': 'test/all/'}\n",
      "spacy_tok <spacy.lang.en.English object at 0x000001F9F2B28F28>\n",
      "TEXT <torchtext.data.field.Field object at 0x000001F9D5CFB9B0>\n"
     ]
    }
   ],
   "source": [
    "PATH='data/aclImdb/'\n",
    "\n",
    "TRN_PATH = 'train/all/'\n",
    "VAL_PATH = 'test/all/'\n",
    "MOD_PATH = 'models/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "MODELS=f'{PATH}{MOD_PATH}'\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH) #TEST AND VALIDATION ARE THE SAME PATH...WHY?\n",
    "\n",
    "spacy_tok = spacy.load('en')\n",
    "TEXT = data.Field(lower=True, tokenize=\"spacy\")\n",
    "\n",
    "def print_project_variables():\n",
    "    print('PATH',PATH)\n",
    "    print('TRN_PATH',TRN_PATH)\n",
    "    print('VAL_PATH',VAL_PATH)\n",
    "    print('TRN',TRN)\n",
    "    print('VAL',VAL)\n",
    "    print('MODELS',MODELS)\n",
    "    print('FILES',FILES)\n",
    "    print('spacy_tok',spacy_tok)\n",
    "    print('TEXT', TEXT)\n",
    "    \n",
    "print_project_variables()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might find it handy to have a function that accept a file path and sample size, returning a dictionary of files and reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_path(sourcepath:str,samplecount:int)->dict:\n",
    "    #YOUR CODE HERE\n",
    "            \n",
    "    return #example_reviews\n",
    "\n",
    "reviews=get_words_from_path(TRN,10)\n",
    "if reviews is not None:\n",
    "    for review in reviews:\n",
    "        print(review,':',reviews[review],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check how many words are in the dataset. We're not returning anything, just looking, so you might want to use !commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running on Windows or are having trouble with the exclamation point calls,you can [make a python function](https://stackoverflow.com/questions/28153549/creating-a-dictionary-of-word-count-of-multiple-text-files-in-a-directory) instead. Expected VAL value: 5686719 (I get a slightly higher value of 5712879 from my python code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(filename:str)->int:\n",
    "    fccount=0\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    return fcount\n",
    "\n",
    "def directory_word_count(directory:str)->int:\n",
    "    dcount=0\n",
    "    #YOUR CODE HERE\n",
    "    # expected VAL value: 5686719\n",
    "    # expected TRN value: 17486581\n",
    "        \n",
    "    return dcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can analyze text, we must first *tokenize* it. This refers to the process of splitting a sentence into an array of words (or more generally, into an array of *tokens*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai works closely with torchtext. We create a ModelData object for language modeling by taking advantage of `LanguageModelData`, passing it our torchtext field object, and the paths to our training, test, and validation sets. In this case, we don't have a separate test set, so we'll just use `VAL_PATH` for that too.\n",
    "\n",
    "As well as the usual `bs` (batch size) parameter, we also not have `bptt`; this define how many words are processing at a time in each row of the mini-batch. More importantly, it defines how many 'layers' we will backprop through. Making this number higher will increase time and memory requirements, but will improve the model's ability to handle long sentences.\n",
    "\n",
    "We use Pytorch's [torchtext](https://github.com/pytorch/text) library to preprocess our data, telling it to use the wonderful [spacy](https://spacy.io/) library to handle tokenization.\n",
    "\n",
    "First, we create a torchtext *field*, which describes how to preprocess a piece of text - in this case, we tell torchtext to make everything lowercase, and tokenize it with spacy.\n",
    "\n",
    "After building our `ModelData` object, it automatically fills the `TEXT` object with a very important attribute: `TEXT.vocab`. This is a *vocabulary*, which stores which words (or *tokens*) have been seen in the text, and how each word will be mapped to a unique integer id. We'll need to use this information again later, so we save it.\n",
    "\n",
    "*(Technical note: python's standard `Pickle` library can't handle this correctly, so at the top of this notebook we used the `dill` library instead)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that accepts a data.Field object and returns the data.Field object updated with a vocabulary and a LanguageModelData object. The function should also accept the path that we'll need to generate the Language Model Data object, the file to save the updated vocabulary to (so we don't have to regenerate it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocab(path:str,\n",
    "                   text:data.Field,\n",
    "                   files:dict,\n",
    "                   vocabsavepath:str=None,\n",
    "                   printsamples=True)->(LanguageModelData, data.Field):\n",
    "    bs=64\n",
    "    bptt=70\n",
    "    min_freq=10\n",
    "    \n",
    "    md=None\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "        \n",
    "    return md,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabpath=MODELS+'TEXT.pkl'\n",
    "md,TEXT=generate_vocab(path=PATH,text=TEXT,files=FILES,vocabsavepath=vocabpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `LanguageModelData` object will create batches with 64 columns (that's our batch size), and varying sequence lengths of around 80 tokens (that's our `bptt` parameter - *backprop through time*).\n",
    "\n",
    "Each batch also contains the exact same data as labels, but one word later in the text - since we're trying to always predict the next word. The labels are flattened into a 1d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(next(iter(md.trn_dl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a number of parameters to set - we'll learn more about these later, but you should find these values suitable for many problems. Researchers have found that large amounts of *momentum* (which we'll learn about later) don't work well with these kinds of *RNN* models, so we'll want to create a version of the *Adam* optimizer with less momentum than the default of `0.9`.\n",
    "\n",
    "fastai uses a variant of the state of the art [AWD LSTM Language Model](https://arxiv.org/abs/1708.02182) developed by Stephen Merity. A key feature of this model is that it provides excellent regularization through [Dropout](https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout). There is no simple way known (yet!) to find the best values of the dropout parameters below - you just have to experiment...\n",
    "\n",
    "However, the other parameters (`alpha`, `beta`, and `clip`) shouldn't generally need tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create functions to load, train and save our model. Add whatever parameters you will find helpful. The get_learner function serves to store the values we use to get our learner model from a LanguageModelData object.  The train_learner function should offer the option to either load or train a module using passed in values. Suggested values are set for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(source_model:LanguageModelData):\n",
    "    learner=None\n",
    "    \n",
    "    #dropout will likely need tuning\n",
    "    dropouti=0.05\n",
    "    dropout=0.05\n",
    "    wdrop=0.1\n",
    "    dropoute=0.02\n",
    "    dropouth=0.05\n",
    "    \n",
    "    \n",
    "    em_sz = 200  # size of each embedding vector\n",
    "    nh = 500     # number of hidden activations per layer\n",
    "    nl = 3       # number of layers\n",
    "    betas=(0.7, 0.99) #used to create a version of the Adam optimizer with less momentum than it's default of 0.9.\n",
    "    opt_fn = partial(optim.Adam, betas=betas)\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    return learner\n",
    "\n",
    "def train_learner(source_model:LanguageModelData):\n",
    "    \n",
    "    learner=get_learner(source_model)\n",
    "    \n",
    "    #these shouldn't need tuning\n",
    "    alpha=2\n",
    "    beta=1\n",
    "    clip=0.3\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "        \n",
    "    return learner\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=train_learner(source_model=md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, I gradually tuned the language model in a few stages. I possibly could have trained it further (it wasn't yet overfitting), but I didn't have time to experiment more. Maybe you can see if you can train it to a better accuracy! (I used `lr_find` to find a good learning rate, but didn't save the output in this notebook. Feel free to try running it yourself now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dd3a8fa5034362978091dba9af3f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4398/4583 [22:58<00:57,  3.19it/s, loss=nan]   "
     ]
    }
   ],
   "source": [
    "#Takes about 30 minutes to run:\n",
    "#learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "learner=train_learner(source_model=md)\n",
    "print(type(learner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sentiment analysis section, we'll just need half of the language model - the *encoder*, so we save that part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling accuracy is generally measured using the metric *perplexity*, which is simply `exp()` of the loss function we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.3926824434624"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(4.165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play around with our language model a bit to check it seems to be working OK. First, let's create a short bit of text to 'prime' a set of predictions. We'll use our torchtext field to numericalize it so we can feed it to our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primethemodel(learner):\n",
    "    ss=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best part\"\"\"\n",
    "    textpath=''#path to text pkl file\n",
    "    \n",
    "    text=None\n",
    "    s = None\n",
    "    t=None\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    return s,t,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodername=''#the name of the text sentiment encoder\n",
    "m=None\n",
    "original_bs=None\n",
    "\n",
    "if learner is not None:\n",
    "    learner.load_encoder(encodername)\n",
    "    m=learner.model\n",
    "    original_bs=m[0].bs\n",
    "\n",
    "s,t,TEXT=primethemodel(learner=learner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s is not None and len(s)>0:\n",
    "    print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_predictions(m):\n",
    "    res=None\n",
    "    # YOUR CODE HERE\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the top 10 predictions were for the next word after our short text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=get_testing_predictions(m)\n",
    "if res is not None:\n",
    "    nexts = torch.topk(res[-1], 10)[1]\n",
    "    [TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and let's see if our model can generate a bit more text all by itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(res,ss,samplesize):\n",
    "    print(ss,\"\\n\")\n",
    "    for i in range(samplesize):\n",
    "        if res is not None:\n",
    "            print(res)\n",
    "        #YOUR CODE HERE\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". So, it wasn't quite was I was expecting, but I really liked it anyway! The best part \n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "ss=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best part\"\"\"\n",
    "generate_text(res,ss,50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to the saved vocab from the language model, since we need to ensure the same words map to the same IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT_SENTIMENT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequential=False` tells torchtext that a text field should be tokenized (in this case, we just want to store the 'positive' or 'negative' single label).\n",
    "\n",
    "`splits` is a torchtext method that creates train, test, and validation sets. The IMDB dataset is built into torchtext, so we can take advantage of that. Take a look at `lang_model-arxiv.ipynb` to see how to define your own fastai/torchtext datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = splits[0].examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos',\n",
       " 'the shining is a weird example of adaptation : it has very little in common with')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.label, ' '.join(t.text[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai can create a ModelData object directly from torchtext splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, m[0].bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsentimentmodel():\n",
    "    dropouti=0.05\n",
    "    dropout=0.05\n",
    "    wdrop=0.1\n",
    "    dropoute=0.02\n",
    "    dropouth=0.05\n",
    "    clip=25\n",
    "\n",
    "    em_sz = 200  # size of each embedding vector\n",
    "    nh = 500     # number of hidden activations per layer\n",
    "    nl = 3       # number of layers\n",
    "    betas=(0.7, 0.99) #used to create a version of the Adam optimizer with less momentum than it's default of 0.9.\n",
    "    opt_fn = partial(optim.Adam, betas=betas)\n",
    "    bs=64\n",
    "    bptt=70\n",
    "    min_freq=10    \n",
    "    \n",
    "    m3 = None\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    return m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're fine-tuning a pretrained model, we'll use differential learning rates, and also increase the max gradient for clipping, to allow the SGDR to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(lrs,m3):\n",
    "    #YOUR CODE HERE\n",
    "    return m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470536ae591640ad872189226391cd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.420445   0.292881   0.875881  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3d8eadeb2d436fb61125ee3668c933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.372781   0.257887   0.894271  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2578866, 0.8942708333333333]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3=finetune(lrs,getsentimentmodel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit our sentiment model using the saved imdb2 cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the imbdb2 cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recent paper from Bradbury et al, [Learned in translation: contextualized word vectors](https://einstein.ai/research/learned-in-translation-contextualized-word-vectors), has a handy summary of the latest academic research in solving this IMDB sentiment analysis problem. Many of the latest algorithms shown are tuned for this specific problem.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "As you see, we just got a new state of the art result in sentiment analysis, decreasing the error from 5.9% to 5.5%! You should be able to get similarly world-class results on other NLP classification problems using the same basic steps.\n",
    "\n",
    "There are many opportunities to further improve this, although we won't be able to get to them until part 2 of this course..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
